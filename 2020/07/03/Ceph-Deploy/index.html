
<!DOCTYPE html>
<html lang="zh-CN" class="loading">
<head>
    <meta charset="UTF-8" />
    <meta name="theme-color" content="#6C9D5E"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>使用 ceph-deploy 部署 Ceph 集群 - S1eke&#39;s Blog</title>
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google" content="notranslate" />
    <meta name="keywords" content="S1eke,"> 
    <meta name="description" content="部署 Ceph 存储集群前置条件
管理节点下需要将所有节点对应的主机名和 IP 写入 hosts 方便批量操作（所有节点需要用不同的主机名）
所有节点配置免密登录方便管理节点使用 ceph-depl,"> 
    <meta name="author" content="Sean Fang"> 
    <link rel="alternative" href="atom.xml" title="S1eke&#39;s Blog" type="application/atom+xml"> 
    <link rel="icon" href="/img/favicon.png"> 
    
    
<link rel="stylesheet" href="/css/diaspora.css">

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({
              google_ad_client: "ca-pub-8691406134231910",
              enable_page_level_ads: true
         });
    </script>
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
<meta name="generator" content="Hexo 5.1.1"></head>


<body class="loading">

    <div class="app-refresh" id="app-refresh">
        <div class="app-refresh-wrap" onclick="location.reload()">
            <label>已更新最新版本</label>
            <span>点击刷新</span>
        </div>
    </div>
    
    <script>
        if ('serviceWorker' in navigator) {
            if (navigator.serviceWorker.controller) {
                navigator.serviceWorker.addEventListener('controllerchange', function() {
                    showNotification();
                });
            }
    
            window.addEventListener('load', function() {
                navigator.serviceWorker.register('/sw.js');
            });
        }
    
        function showNotification() {
            document.querySelector('meta[name=theme-color]').content = '#000';
            document.getElementById('app-refresh').className += ' app-refresh-show';
        }
    </script>
    
    <span id="config-title" style="display:none">S1eke&#39;s Blog</span>
    <div id="loader"></div>
    <div id="single">
    <div id="top" style="display: block;">
    <div class="bar" style="width: 0;"></div>
    <a class="iconfont icon-home image-icon" href="javascript:;" data-url="https://blog.jugg.xyz"></a>
    <div title="播放/暂停" class="iconfont icon-play"></div>
    <h3 class="subtitle">使用 ceph-deploy 部署 Ceph 集群</h3>
    <div class="social">
        <div>
            <div class="share">
                <a title="获取二维码" class="iconfont icon-scan" href="javascript:;"></a>
            </div>
            <div id="qr"></div>
        </div>
    </div>
    <div class="scrollbar"></div>
</div>

    <div class="section">
        <div class="article">
    <div class='main'>
        <h1 class="title">使用 ceph-deploy 部署 Ceph 集群</h1>
        <div class="stuff">
            <span>七月 03, 2020</span>
            
  <ul class="post-tags-list" itemprop="keywords"><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/Ceph/" rel="tag">Ceph</a></li><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/Linux/" rel="tag">Linux</a></li></ul>


        </div>
        <div class="content markdown">
            <h1 id="部署-Ceph-存储集群"><a href="#部署-Ceph-存储集群" class="headerlink" title="部署 Ceph 存储集群"></a>部署 Ceph 存储集群</h1><h2 id="前置条件"><a href="#前置条件" class="headerlink" title="前置条件"></a>前置条件</h2><ol>
<li>管理节点下需要将所有节点对应的主机名和 IP 写入 hosts 方便批量操作（所有节点需要用不同的主机名）</li>
<li>所有节点配置免密登录方便管理节点使用 ceph-deploy 部署(用户需要有sudo权限，并且是NOPASSWD)</li>
</ol>
<h2 id="重置环境（仅在原环境上操作需要使用）"><a href="#重置环境（仅在原环境上操作需要使用）" class="headerlink" title="重置环境（仅在原环境上操作需要使用）"></a>重置环境（仅在原环境上操作需要使用）</h2><p>该操作需要在集群的管理节点的 ceph-deploy 目录下操作。</p>
<ol>
<li><p>删除所有节点的ceph软件 </p>
<pre><code> $ ceph-deploy purge &#123;ceph-node&#125; [&#123;ceph-node&#125;]</code></pre>
</li>
<li><p>删除所有节点的ceph软件数据</p>
<pre><code> $ ceph-deploy purgedata &#123;ceph-node&#125; [&#123;ceph-node&#125;]</code></pre>
</li>
<li><p>删除所有节点的keys</p>
<pre><code> $ ceph-deploy forgetkeys</code></pre>
</li>
<li><p>删除ceph配置文件</p>
<pre><code> $ rm ceph.*</code></pre>
</li>
</ol>
<h2 id="自动部署（ceph-deploy）"><a href="#自动部署（ceph-deploy）" class="headerlink" title="自动部署（ceph-deploy）"></a>自动部署（ceph-deploy）</h2><h3 id="安装-ceph-deploy"><a href="#安装-ceph-deploy" class="headerlink" title="安装 ceph-deploy"></a>安装 ceph-deploy</h3><pre><code># pip install ceph-deploy</code></pre>
<hr>
<h3 id="存储集群"><a href="#存储集群" class="headerlink" title="存储集群"></a>存储集群</h3><p>由于官方的源再国内访问所以需要使用第国内供的软件源，通过配置环境变量使用 aliyun 提供的 ceph-mimic 版本的仓库。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">export</span> CEPH_DEPLOY_REPO_URL=https://mirrors.aliyun.com/ceph/debian-mimic</span></span><br></pre></td></tr></table></figure>

<h4 id="创建集群"><a href="#创建集群" class="headerlink" title="创建集群"></a>创建集群</h4><p>先在管理节点上创建一个目录，用于保存 ceph-deploy 生成的配置文件和密钥对。</p>
<pre><code># mkdir my-cluster
# cd my-cluster</code></pre>
<p>然后开始创建监控节点：</p>
<pre><code># ceph-deploy new 监控节点主机名</code></pre>
<p>这里需要把所有设备配置好免密登录，以及把所有设备的主机名和IP的对应关系写入管理节点的 hosts ，防止网络发现没有生效。另外因为 ceph-deploy 是直接调用 ssh 远程操作节点，而且会使用 sudo ，而且不支持 root 登录（官方的口径是 root 不支持 sudo ，但是实际上是可以用的。），所以要配置好用户的 sudo 免密操作。</p>
<h4 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h4><p>ceph 自带的容灾配置，默认是保存三份副本，可以把 <code>osd pool default size = 3</code> 写入 Ceph 配置文件的 <code>[global]</code> 段下。更改为其他数量。</p>
<p>另外如果你有多个网卡，也可以可以把 public network 写入 Ceph 配置文件的 <code>[global]</code> 段下。</p>
<p>以下是我的配置文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[global]</span><br><span class="line">fsid = aa7852b8-dd0b-40d4-a2f4-bd1f38c6dc69</span><br><span class="line">mon_initial_members = node3, node4</span><br><span class="line">mon_host = 192.168.1.3,192.168.1.4</span><br><span class="line">auth_cluster_required = cephx</span><br><span class="line">auth_service_required = cephx</span><br><span class="line">auth_client_required = cephx</span><br><span class="line">osd pool default pg num = 4096</span><br><span class="line">osd pool default pgp num = 4096</span><br><span class="line">osd pool default size = 3</span><br><span class="line">mon_allow_pool_delete = true</span><br><span class="line">mon clock drift allowed = 0.1</span><br><span class="line">mon data avail warn = 10</span><br><span class="line">osd pool default min size = 1</span><br></pre></td></tr></table></figure>


<h4 id="为所有节点安装-Ceph"><a href="#为所有节点安装-Ceph" class="headerlink" title="为所有节点安装 Ceph"></a>为所有节点安装 Ceph</h4><pre><code># ceph-deploy install 所有节点主机名（包括管理节点）</code></pre>
<h4 id="配置初始-monitor-s-、并收集所有密钥"><a href="#配置初始-monitor-s-、并收集所有密钥" class="headerlink" title="配置初始 monitor(s)、并收集所有密钥"></a>配置初始 monitor(s)、并收集所有密钥</h4><pre><code># ceph-deploy mon create-initial</code></pre>
<p>如有报错，请检查管理节点的 /etc/hosts、~/.ssh/config 里的所有主机名和 IP 与监控节点的主机名和 IP 名一致。另外还有多个节点</p>
<hr>
<h3 id="创建集群-1"><a href="#创建集群-1" class="headerlink" title="创建集群"></a>创建集群</h3><h4 id="分发管理节点的配置以及密钥"><a href="#分发管理节点的配置以及密钥" class="headerlink" title="分发管理节点的配置以及密钥"></a>分发管理节点的配置以及密钥</h4><pre><code># ceph-deploy admin  所有节点名</code></pre>
<h4 id="为监控节点部署管理器守护程序"><a href="#为监控节点部署管理器守护程序" class="headerlink" title="为监控节点部署管理器守护程序"></a>为监控节点部署管理器守护程序</h4><pre><code># ceph-deploy mgr create 所有监控节点</code></pre>
<h4 id="创建-OSD"><a href="#创建-OSD" class="headerlink" title="创建 OSD"></a>创建 OSD</h4><pre><code># ceph-deploy osd create --data &#123;device&#125; &#123;ceph-node&#125;

示例：ceph-deploy osd create --data /dev/sdb node30</code></pre>
<p>OSD 创建完毕后再检查一些集群的健康情况(当使用ceph时需要使用管理员权限)：</p>
<pre><code># ceph health</code></pre>
<p>也可以用 <code>ceph -s</code> 查看集群的详细信息。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">vm@Lotus-Master ~/my-cluster % sudo ceph -s</span><br><span class="line">  cluster:</span><br><span class="line">    id:     8d24cae1-07a9-4c3c-a74c-d0b56e4ad243</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line"></span><br><span class="line">  services:</span><br><span class="line">    mon: 2 daemons, quorum node3,node4 (age 2m)</span><br><span class="line">    mgr: node7(active, since 43m), standbys: node8, node9, node10, node11, node12, node15, node16, node6, node14, node18, Lotus-Master, node3, node5, node4</span><br><span class="line">    osd: 14 osds: 14 up (since 2m), 14 in (since 15m)</span><br><span class="line"></span><br><span class="line">  data:</span><br><span class="line">    pools:   0 pools, 0 pgs</span><br><span class="line">    objects: 0 objects, 0 B</span><br><span class="line">    usage:   14 GiB used, 114 TiB / 114 TiB avail</span><br><span class="line">    pgs:</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="创建-Cephfs"><a href="#创建-Cephfs" class="headerlink" title="创建 Cephfs"></a>创建 Cephfs</h2><h3 id="创建-mds-节点"><a href="#创建-mds-节点" class="headerlink" title="创建 mds 节点"></a>创建 mds 节点</h3><pre><code># ceph-deploy mds create &#123;ceph-node&#125;</code></pre>
<p>CephFS 中的所有元数据操作都通过 mds 进行，因此至少需要一台 mds 节点。为了防止单点故障，在这里可以配置多个mds 服务器。默认的</p>
<h3 id="创建-pool"><a href="#创建-pool" class="headerlink" title="创建 pool"></a>创建 pool</h3><pre><code># ceph osd pool create cephfs_data 2048
# ceph osd pool create cephfs_meta 512</code></pre>
<p>创建了一个名为 cephfs_data 和一个名为 cephfs_meta 的 pool 。关于 pg 数量的配置公式如下。当使用公式计算时，pg 数一定要是贴近计算值的2的指数值。譬如有两百个 OSD ，两个 pool ，三个副本，则计算值为200*100/2/3=4000，pg 值应设置为最接近 4000 的 2 的指数值 4096。其中 cephfs 的 data pool 和 metadata pool 的 pg 数按 <a target="_blank" rel="noopener" href="http://lists.ceph.com/pipermail/ceph-users-ceph.com/2017-March/016965.html">ceph官方邮件</a> 讨论中来说，建议是 4：1 的比例。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">                         (OSDs * 100)</span><br><span class="line">Total PGs &#x3D;  ---------------------------------------</span><br><span class="line">              (pool count) * (max replication count)</span><br></pre></td></tr></table></figure>

<p>另外可通过 <code>sudo ceph osd lspools</code> 来查看已有的 pool，如果要删除 pool 可以使用以下命令：</p>
<pre><code>#  ceph osd pool delete  cephfs_data cephfs_data --yes-i-really-really-mean-it</code></pre>
<h3 id="创建-cephfs"><a href="#创建-cephfs" class="headerlink" title="创建 cephfs"></a>创建 cephfs</h3><pre><code># ceph fs new mycephfs cephfs_meta cephfs_data</code></pre>
<h3 id="挂载-cephfs"><a href="#挂载-cephfs" class="headerlink" title="挂载 cephfs"></a>挂载 cephfs</h3><p>监控节点的密钥可以通过在监控节点执行 “sudo cat /etc/ceph/ceph.client.admin.keyring|grep key|cut -d” “ -f3” 获取。</p>
<pre><code># mount -t ceph 监控节点IP:6789:/ 目录挂载点 -o name=admin,secret=&quot;监控节点密钥&quot;,acl,async,rw,noexec,nodev,noatime,nodiratime</code></pre>
<p>示例：</p>
<pre><code># mount -t ceph 192.168.1.30:6789,192.168.1.32:6789,192.168.1.34:6789,192.168.1.35:6789,192.168.1.37:6789:/ /lotus -o name=admin,secret=&quot;AQCyVdde8Y5EDBAAQCrFCJYVsmXZHAZC+4mAJQ==&quot;,acl,async,rw,noexec,nodev,noatime,nodiratime</code></pre>
<hr>
<h2 id="实施中遇到的其他问题"><a href="#实施中遇到的其他问题" class="headerlink" title="实施中遇到的其他问题"></a>实施中遇到的其他问题</h2><ol>
<li><p>用parted分区后的分区表不会立即生效，需要重启。如果不想重启，可以使用 <code>partprobe</code> 命令，此命令可以让系统内核重新读取分区表信息，就不用重新启动电脑。</p>
</li>
<li><p>如果硬盘在使用之前已经有了 GPT 分区创建 OSD 的时候就会报报 <code>error: GPT headers found</code> ，这时可以直接用 dd 将 GPT 分区删掉：</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> dd <span class="keyword">if</span>=/dev/zero of=/dev/sdb bs=512K count=1</span></span><br></pre></td></tr></table></figure>

<p> 如果需要添加的硬盘在已存在的lvm卷组里，譬如重置环境后需要加入新的集群的 osd ，可以用以下命令先脱离 lvm ，再删除GPT分区：</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> lvremove -vf `lvdisplay|grep <span class="string">&quot;LV Path&quot;</span>|awk <span class="string">&#x27;&#123;print $3&#125;&#x27;</span>`</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> vgremove -vf `vgdisplay|grep <span class="string">&quot;VG Name&quot;</span>|awk <span class="string">&#x27;&#123;print $3&#125;&#x27;</span>`</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> pvremove -vf `pvdisplay|grep <span class="string">&quot;PV Name&quot;</span>|awk <span class="string">&#x27;&#123;print $3&#125;&#x27;</span>`</span></span><br></pre></td></tr></table></figure>


</li>
</ol>
<ol start="3">
<li>修改 ceph.conf后要使用 <code>ceph-deploy --overwrite-conf config push 所有节点名称</code> 来把新配置推送到所有节点上。</li>
</ol>
<ol start="4">
<li><p>如果删除 pool 报错 <code>Error EPERM: pool deletion is disabled; you must first set the mon_allow_pool_delete config option to true before you can destroy a pool</code> ，则可以添加 <code>mon_allow_pool_delete = true</code> 到 ceph.conf ，然后执行 <code>ceph osd pool delete  lotus lotus --yes-i-really-really-mean-it</code> ，或者用下面的方法</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ceph tell mon.\* injectargs <span class="string">&#x27;--mon-allow-pool-delete=true&#x27;</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> ceph osd pool delete  lotus lotus --yes-i-really-really-mean-it</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>错误：</p>
<pre><code> # rbd: create error: (33) Numerical argument out of domain
 # 2020-03-09 22:38:32.177 7fe1a39ecf40 -1 librbd::image::CreateRequest: validate_order: order must be in the range [12, 25]</code></pre>
<p> 原因：<code>rbd_default_order</code> 配置过高，这个配置项决定了集群内切块的大小，默认是22，范围是[12, 25]，不在这个范围都会报错。</p>
</li>
<li><p>错误：集群大小与实际存储容量不符合</p>
<p>原因：RBD 进行数据删除的时候实际上并不会直接删除对象，而是给对象打上已删除的标记，所以删除内容还是在集群内占用空间。这里需要通过文件系统去主动释放被标记为已删除的对象 <code>sudo fstrim rbd挂载目录</code> 。</p>
</li>
<li><p>错误：pg 数设置错误，需要调整</p>
<p>解决方法（另外这里需要注意，pg 数不能一次性扩大太多，每次调整的大小尽量不要超过100%）：</p>
<pre><code> # ceph osd pool set cephfs_data pg_num 4096
 # ceph osd pool set cephfs_data pgp_num 4096</code></pre>
</li>
<li><p>错误：监控节点数量添加少了，需要调整</p>
<p>解决方法：</p>
<pre><code> # ceph-deploy mon add 新增监视器主机名</code></pre>
<p> 这里有一点要注意，所有监视器一定要设置 NTP 同步，尽量选择同一个 NTP 服务器进行同步。</p>
<p> 而一旦添加了新的Ceph监视器，Ceph将开始同步监视器并形成仲裁。可以通过执行以下操作检查仲裁状态：</p>
<pre><code> # ceph quorum_status --format json-pretty</code></pre>
</li>
<li><p>错误：cephfs出现错误需要重建，删除pool却显示pool正在被cephfs使用中</p>
<p>解决方法：</p>
<p> 首先停止mds的服务</p>
<pre><code> # systemctl stop ceph-mds@$HOSTNAME</code></pre>
<p> 然后 设置mds为失败</p>
<pre><code> # ceph mds fail 0    </code></pre>
<p> 接着删除cephfs</p>
<pre><code> # ceph fs rm mycephfs --yes-i-really-mean-it  </code></pre>
<p> 然后删除cephfs使用的pool</p>
<pre><code> # ceph osd pool delete  lotus lotus --yes-i-really-really-mean-it</code></pre>
</li>
</ol>
<hr>

            <!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
            <audio id="audio" loop="1" preload="auto" controls="controls" data-autoplay="false">
                <source type="audio/mpeg" src="">
            </audio>
            
                <ul id="audio-list" style="display:none">
                    
                        
                            <li title='0' data-url='https://music.163.com/song/media/outer/url?id=101906.mp3'></li>
                        
                    
                </ul>
            
        </div>
        
    <div id='gitalk-container' class="comment link"
		data-enable='false'
        data-ae='false'
        data-ci=''
        data-cs=''
        data-r=''
        data-o=''
        data-a=''
        data-d='false'
    >查看评论</div>


    </div>
    
</div>


    </div>
</div>
</body>


<script src="//lib.baomitu.com/jquery/1.8.3/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/typed.js"></script>
<script src="/js/diaspora.js"></script>


<link rel="stylesheet" href="/photoswipe/photoswipe.css">
<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">


<script src="/photoswipe/photoswipe.min.js"></script>
<script src="/photoswipe/photoswipe-ui-default.min.js"></script>


<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>





<!-- Google Analytics -->
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-117507587-1', 'auto');
  ga('send', 'pageview');
</script>
<!-- End Google Analytics -->


</html>
